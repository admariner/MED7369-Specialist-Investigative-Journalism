{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"anExampleScraperList.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNunoh/vojdqfNJ5ErDYnOk"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fAT7xLYe_scU"},"source":["# An example scraper using a list\n","\n","The code below can be copied and adapted to create your own scraper.\n","\n","The first part installs all the libraries. I've kept this separate to the other parts so that you don't have to install them every time you want to run the scraper itself."]},{"cell_type":"code","metadata":{"id":"sE2vW-IX9kYX","executionInfo":{"status":"ok","timestamp":1647285891099,"user_tz":0,"elapsed":824,"user":{"displayName":"Paul Bradshaw","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYQSCAPAX7cikAjthcRciH5mrSmVPNLmT_aEplrw=s64","userId":"01457212023850926122"}}},"source":["#install the libraries \n","#requests is a library for fetching webpages from a URL\n","import requests\n","#BeautifulSoup is a library for scraping webpages\n","from bs4 import BeautifulSoup\n","#the pandas library which is used to work with data - we call it 'pd' here so we have to type less!\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2MTFOTQUh2UH"},"source":["## Using a list\n","\n","Below we write some code to create a list of counties that can be used to generate URLs on a karting site.\n","\n","We also store the 'base URL' that we will add to each item in the list to create a full URL."]},{"cell_type":"code","metadata":{"id":"RO6lht-cgc4A","executionInfo":{"status":"ok","timestamp":1647285893766,"user_tz":0,"elapsed":325,"user":{"displayName":"Paul Bradshaw","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYQSCAPAX7cikAjthcRciH5mrSmVPNLmT_aEplrw=s64","userId":"01457212023850926122"}}},"source":["#create a list of counties that we will need to generate URLs\n","counties = [\"avon\",\"bedfordshire\",\"berkshire\",\"birmingham\"]\n","#store the base URL we will add those to\n","baseurl = \"http://www.uk-go-karting.com/tracks/\""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sn8Zsx4fiC_u"},"source":["## Using a loop\n","\n","Next we loop through each item in the list and add it to that base url using the `+` operator.\n","\n","We add a `print` function inside the loop to check that it works each time - and copy those links into a browser to check that they are the right links."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sRa5dxGOg2ZI","executionInfo":{"status":"ok","timestamp":1647285895533,"user_tz":0,"elapsed":242,"user":{"displayName":"Paul Bradshaw","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYQSCAPAX7cikAjthcRciH5mrSmVPNLmT_aEplrw=s64","userId":"01457212023850926122"}},"outputId":"651a1ea7-20e7-4e54-caff-c5c9867a5c34"},"source":["#start looping through our list\n","for county in counties:\n","  fullurl = baseurl+county\n","  print(fullurl)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["http://www.uk-go-karting.com/tracks/avon\n","http://www.uk-go-karting.com/tracks/bedfordshire\n","http://www.uk-go-karting.com/tracks/berkshire\n","http://www.uk-go-karting.com/tracks/birmingham\n"]}]},{"cell_type":"markdown","metadata":{"id":"_5s0_uuJiNIl"},"source":["## Scraping each URL as we loop\n","\n","Now that we know the loop works in generating the right URLs, we can extend the code inside the loop so that it *scrapes* each URL.\n","\n","At this point we are using some of the libraries we imported at the start. `requests.get()`, for example, is the `get()` function from the `requests` library. \n","\n","Let's look at the code first, and then explain it..."]},{"cell_type":"code","metadata":{"id":"9Yw0QKTJ_qpu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647285977976,"user_tz":0,"elapsed":6460,"user":{"displayName":"Paul Bradshaw","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYQSCAPAX7cikAjthcRciH5mrSmVPNLmT_aEplrw=s64","userId":"01457212023850926122"}},"outputId":"6a01cfea-6b60-44f2-dd53-71fa4c066e46"},"source":["#start looping through our list\n","for county in counties:\n","  fullurl = baseurl+county\n","  print(fullurl)\n","  #Scrape the html at that url\n","  html = requests.get(fullurl)\n","  # turn our HTML into a BeautifulSoup object\n","  soup = BeautifulSoup(html.content) \n","  #The names are all in <h2> and then <a \n","  #This targets the contents of those html tags\n","  addresses = soup.select('h2 a')\n","  #the results are always a list so we have to loop through it using a 'for' loop\n","  for i in addresses:\n","    #each item in the list is called i as it loops\n","    print(i)\n","    #on its own it includes tags, but we can attach .get_text() to translate it into text\n","    address = i.get_text()\n","    print(address)\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["http://www.uk-go-karting.com/tracks/avon\n","<a href=\"http://www.uk-go-karting.com/tracks/avon/the-raceway\">Bristol Go Karting</a>\n","Bristol Go Karting\n","http://www.uk-go-karting.com/tracks/bedfordshire\n","<a href=\"http://www.uk-go-karting.com/tracks/bedfordshire/dunstable-go-karting\">Dunstable Go Karting</a>\n","Dunstable Go Karting\n","http://www.uk-go-karting.com/tracks/berkshire\n","<a href=\"http://www.uk-go-karting.com/tracks/berkshire/reading-go-karting\">Reading Go Karting</a>\n","Reading Go Karting\n","http://www.uk-go-karting.com/tracks/birmingham\n","<a href=\"http://www.uk-go-karting.com/tracks/birmingham/teamworks-karting-birmingham\">Teamworks Karting Birmingham (Central)</a>\n","Teamworks Karting Birmingham (Central)\n","<a href=\"http://www.uk-go-karting.com/tracks/birmingham/grand-prix-karting\">Grand Prix Karting</a>\n","Grand Prix Karting\n","<a href=\"http://www.uk-go-karting.com/tracks/birmingham/birmingham-go-karting\">Birmingham Go Karting</a>\n","Birmingham Go Karting\n","<a href=\"http://www.uk-go-karting.com/tracks/birmingham/tamworth-karting\">Daytona Tamworth Karting</a>\n","Daytona Tamworth Karting\n"]}]},{"cell_type":"markdown","metadata":{"id":"tDFgv8F5kt6U"},"source":["## The functions we are using\n","\n","Let's break some of this down.\n","\n","So `requests.get()` is the `get()` function from the `requests` library. The *ingredient* we give to that function is the URL we stored in the `fullurl` variable.\n","\n","The `get()` function basically fetches the whole webpage at a given address (the ingredient it's given).\n","\n","The results of running that function are stored in a new variable called `html`.\n","\n","This isn't in a form we can easily work with, yet, so we need another function to convert it to something we can drill down into. \n","\n","That function is the `BeautifulSoup()` function.\n","\n","*(This is actually from the `bs4` library but we don't need to name it because we imported the function specifically earlier when we wrote `from bs4 import BeautifulSoup`)*\n","\n","The *ingredient* we give to that `BeautifulSoup` function is the `html` variable we just created - but we need to add `.content` to specify we want the content of that page.\n","\n","The results are stored in another new variable, `soup`.\n","\n","This variable is a particular type of object (a \"BeautifulSoup object\" if you need to know) that can be drilled down into using the `.select()` function that BeautifulSoup objects possess. \n","\n","That `.select()` function will grab elements that match the *CSS selectors* that you give it as an ingredient.\n","\n","In this case we specify `'h2 a'`, which means \"any a tag within a h2 tag\" - so it will grab the contents of any links inside h2 tags in the page.\n","\n","Don't worry about memorising any of the code above: this is code that you can re-use time and time again. The only bit you will need to change is the selector, in order to specify the particular HTML you're after. \n","\n","To work out the selector you need, you'll often need to Google around, learning as you go, but selectors are pretty easy to get the hang of, and I'll talk about it more below."]},{"cell_type":"markdown","metadata":{"id":"U1n21e_LWI-A"},"source":["## Using CSS selectors\n","\n","**CSS selectors** are used to target different elements in a HTML page. A basic selector can target just one type of HTML tag, like `<h2>` or `<p>`, but you can also target a combination of tags (such as any `<strong>` tags within `<p>` tags). \n","\n","More complicated selectors can also be used to target tags based on their attributes (e.g. not just `<p>` but specifically `<p class=\"summary\">`).\n","\n","You can find lots of resources to help you with CSS selectors, such as [this one](https://www.w3schools.com/cssref/css_selectors.asp). Many will relate to styling webpages (which is how CSS selectors are most often used - selectors are used to target the HTML elements that you want to style), but the principles are the same.\n"]},{"cell_type":"markdown","metadata":{"id":"HQpygiZfYeT4"},"source":["## Saving the information we've grabbed.\n","\n","Now we've grabbed some information we can extend the code further to save it.\n","\n","At this point we need to use functions from another library: `pandas`. This is a library for data storage and analysis. When we imported `pandas` we called it `pd` for short. This is quite common. Any reference to `pd` in the code, then, means `pandas`\n","\n","First, we use the function `DataFrame()` which creates a pandas dataframe. As ingredients it needs to know the names of any columns.\n","\n","You will see below that we add a line *before* the loop which uses that to create an empty dataframe to store the data in.\n","\n","Then, inside the loop, the data we extract is added to the dataframe.\n","\n","Here's the code first - then I'll explain the new bits after.\n"]},{"cell_type":"code","metadata":{"id":"c_hvHkNqhc0B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647287037017,"user_tz":0,"elapsed":4879,"user":{"displayName":"Paul Bradshaw","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYQSCAPAX7cikAjthcRciH5mrSmVPNLmT_aEplrw=s64","userId":"01457212023850926122"}},"outputId":"a4a5f75a-03e9-4bb9-a15c-01495cb2fe15"},"source":["#create an empty list to store our addresses\n","addresslist = []\n","\n","#start looping through our list\n","for county in counties:\n","  fullurl = baseurl+county\n","  print(fullurl)\n","  #Scrape the html at that url\n","  html = requests.get(fullurl)\n","  # turn our HTML into a BeautifulSoup object\n","  soup = BeautifulSoup(html.content) \n","  #The names are all in <h3> - a change from our previous code\n","  #This targets the contents of those html tags\n","  addresses = soup.select('h3')\n","  #the results are always a list so we have to loop through it using a 'for' loop\n","  for i in addresses:\n","    #each item in the list is called i as it loops\n","    print(i)\n","    #on its own it includes tags, but we can attach .get_text() to translate it into text\n","    address = i.get_text()\n","    print(address)\n","    #add to the previously empty list\n","    addresslist.append(address)\n","\n","#Create a dataframe to store the data we scraped\n","#It has one column called 'location'\n","#We store the list 'addresslist' in that column\n","#We call this dataframe 'df'\n","df = pd.DataFrame({\"location\": addresslist})\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["http://www.uk-go-karting.com/tracks/avon\n","<h3>Avonmouth Way, Bristol, Avon BS11 9YA</h3>\n","Avonmouth Way, Bristol, Avon BS11 9YA\n","http://www.uk-go-karting.com/tracks/bedfordshire\n","<h3>Unit 27, Verey Road, Woodside Industrial Estate, Dunstable, Bedfordshire LU5 4TT</h3>\n","Unit 27, Verey Road, Woodside Industrial Estate, Dunstable, Bedfordshire LU5 4TT\n","http://www.uk-go-karting.com/tracks/berkshire\n","<h3>Cradock Road, Reading, Berkshire RG2 0EE</h3>\n","Cradock Road, Reading, Berkshire RG2 0EE\n","http://www.uk-go-karting.com/tracks/birmingham\n","<h3>Fazeley Street, Birmingham B5 5SE</h3>\n","Fazeley Street, Birmingham B5 5SE\n","<h3>Adderley Road South, Birmingham B8 1AD</h3>\n","Adderley Road South, Birmingham B8 1AD\n","<h3>Park Lane, Oldbury, Birmingham B69 4JX</h3>\n","Park Lane, Oldbury, Birmingham B69 4JX\n","<h3>Robeys Lane, Tamworth,  B78 1AR</h3>\n","Robeys Lane, Tamworth,  B78 1AR\n"]}]},{"cell_type":"markdown","metadata":{"id":"omuqBRQKZW8h"},"source":["## The new code\n","\n","The first line of new code is this:\n","\n","```\n","addresslist = []\n","```\n","\n","We are creating a new variable here, called `addresslist`, and assigning to it a list, indicated by the square brackets. \n","\n","The square brackets are empty, however, which means this is an *empty list*.\n","\n","The second line of new code sits inside the loop, so it will run each time the loop runs. It is this:\n","\n","```\n","addresslist.append(address)\n","```\n","\n","Here we see our empty list - but this time it is attached to the `.append()` function which will add something to that list. Here it adds `address`. \n","\n","The first time this loop runs, then, it will add whatever is inside the `address` variable to the list `addresslist`. It will then have one item instead of being ann empty list.\n","\n","But that loop will run a number of times, and each time that list will grow by one item. \n","\n","Once the loop has finished we get to a third and final extra line of code:\n","\n","```\n","df = pd.DataFrame({\"location\": addresslist})\n","```\n","\n","This creates another new variable called `df` - and assigns to it the results of using a function: `pd.DataFrame()` \n","\n","This is a function called `DataFrame` from the `pandas` library (remember we called it `pd`).\n","\n","That takes an ingredient: a **dictionary**. \n","\n","A dictionary is like a list, but with two key differences: firstly that it uses curly brackets instead of square ones: `{}`, and secondly it's a list of *pairs*: a 'key', and a 'value', separated by a colon.\n","\n","Here's the dictionary in our code:\n","\n","`{\"location\": addresslist}`\n","\n","The first part, `\"location\"` is the **key**. This is the column heading. Note that it's a **string**: a label, basically.\n","\n","The second part, `addresslist`, is the **value**. This isn't in quotes so it's not a string - it's a variable: the variable we created earlier, and then added to within our list. \n","\n","So having extracted that information and stored it in `addresslist`, the line of code is storing it in a dataframe with the label (key) \"location\":\n","\n","We can print the dataframe to see what's in there:\n"]},{"cell_type":"code","metadata":{"id":"FIdecPU__881","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647287042508,"user_tz":0,"elapsed":249,"user":{"displayName":"Paul Bradshaw","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYQSCAPAX7cikAjthcRciH5mrSmVPNLmT_aEplrw=s64","userId":"01457212023850926122"}},"outputId":"484cc901-2107-48c4-a74d-12dbf460415e"},"source":["#Once the loop has finished we can take a look at the data\n","print(df)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["                                            location\n","0              Avonmouth Way, Bristol, Avon BS11 9YA\n","1  Unit 27, Verey Road, Woodside Industrial Estat...\n","2           Cradock Road, Reading, Berkshire RG2 0EE\n","3                  Fazeley Street, Birmingham B5 5SE\n","4             Adderley Road South, Birmingham B8 1AD\n","5             Park Lane, Oldbury, Birmingham B69 4JX\n","6                    Robeys Lane, Tamworth,  B78 1AR\n"]}]},{"cell_type":"markdown","metadata":{"id":"Bh73Sbovc9To"},"source":["## Exporting the data\n","\n","The `pandas` library has another function for exporting data: `to_csv()`.\n","\n","It needs to be attached to the name of the dataframe variable with a period, then, in the brackets, you specify the name of the file you want to export it as. Make sure this ends in '.csv' so it can be used in a spreadsheet."]},{"cell_type":"code","metadata":{"id":"i9FDGDX0__eA","executionInfo":{"status":"ok","timestamp":1647287111491,"user_tz":0,"elapsed":233,"user":{"displayName":"Paul Bradshaw","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYQSCAPAX7cikAjthcRciH5mrSmVPNLmT_aEplrw=s64","userId":"01457212023850926122"}}},"source":["#And we can export it\n","df.to_csv(\"scrapeddata.csv\")"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wCtq8ih5dNaE"},"source":["## Downloading the data\n","\n","Once exported, it should appear in the file explorer in Google Colab on the left hand side. Click on the folder icon to open this up and you should see the file you just created (there's a refresh button above if you can't).\n","\n","Hover over the file name to see three dots, then click on those to select **Download** and download to your computer."]},{"cell_type":"markdown","metadata":{"id":"eq60rrHrAoeN"},"source":["## How to adapt it\n","\n","You can use most of this code without having to change it. All you *need* to change is the lines specifying the base URL, and the list of words to add to it.\n","\n","And this line, which specifies what you want to scrape from that page:\n","\n","`titles = root.cssselect('h2')`\n","\n","If you're scraping one type of information from one page, that will be enough. \n","\n","For the CSS selector you will need to identify the HTML in the page you are scraping, and the combination of tags that is being used. \n","\n","Some [reading around CSS selectors](https://www.w3schools.com/cssref/css_selectors.asp) will help you here, but a couple of useful things to know include:\n","\n","* A period `.` means `class=\"`\n","* A hash `#` means `id=\"`\n","\n","So `'div.title a'` means `<div class=\"title\"><a ...>` - or, in other words, anything on the page inside an `<a>` tag (a link) within a `<div class=\"title\">` tag.\n","\n","The words used for variables (like \"baseurl\" and \"titles\" above) may not be relevant to what you are scraping - but that doesn't matter, because those words are arbitrary. If you do decide to change them, make sure you change them *throughout* the code, or it will create an error.\n"]},{"cell_type":"markdown","metadata":{"id":"nE35f1sxgV6Q"},"source":["## Generating URLs for a scraper to loop through\n","\n","Alternatively you might *generate* the URLs: for example, if they end in a number that goes up by 1 each time you can use `range` to generate that list of numbers and add them to the URL using `+`.\n","\n","However, you cannot mix numbers and strings, so you need to convert the numbers to a string as you do this. Here's an example:"]},{"cell_type":"code","metadata":{"id":"rUcpB_cPNwq5","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"error","timestamp":1647287146983,"user_tz":0,"elapsed":246,"user":{"displayName":"Paul Bradshaw","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYQSCAPAX7cikAjthcRciH5mrSmVPNLmT_aEplrw=s64","userId":"01457212023850926122"}},"outputId":"2d734f3d-a1e8-4793-9d58-bfafb9ad81a7"},"source":["#Create the basic URL that appears before the number\n","baseurl = \"http://mypage.com?page=\"\n","#Create a list of numbers to put on the end\n","pagenums = range(1,11)\n","#Now generate the URLs by looping through the list and adding it to the URL\n","for i in pagenums:\n","  #Combine the two - \n","  #this will generate an error because we are trying to combine a string and a number\n","  fullurl = baseurl+i"],"execution_count":9,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-9337eb8598a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#Combine the two -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#this will generate an error because we are trying to combine a string and a number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mfullurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseurl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"]}]},{"cell_type":"markdown","metadata":{"id":"KshYh7u7ON5d"},"source":["## Tip: converting numbers into strings\n","\n","You can see the error `must be str, not int` - in other words the second part must be a string not an integer.\n","\n","To fix that you can use the `str()` function, which will convert a number into a string."]},{"cell_type":"code","metadata":{"id":"HyuZ131lOW3w","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1582615358634,"user_tz":0,"elapsed":518,"user":{"displayName":"Paul Bradshaw","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCETKNgzd5HPQJUeaZqCSPaUEkiC0g6gchznw_efA=s64","userId":"01457212023850926122"}},"outputId":"475d3e46-8694-42eb-f546-23e7cc7882d5"},"source":["#Create the basic URL that appears before the number\n","baseurl = \"http://mypage.com?page=\"\n","#Create a list of numbers to put on the end\n","pagenums = range(1,11)\n","#Now generate the URLs by looping through the list and adding it to the URL\n","for i in pagenums:\n","  #Convert i to a string\n","  i = str(i)\n","  #Combine the two\n","  fullurl = baseurl+i\n","  #print it\n","  print(fullurl)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["http://mypage.com?page=1\n","http://mypage.com?page=2\n","http://mypage.com?page=3\n","http://mypage.com?page=4\n","http://mypage.com?page=5\n","http://mypage.com?page=6\n","http://mypage.com?page=7\n","http://mypage.com?page=8\n","http://mypage.com?page=9\n","http://mypage.com?page=10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BOvob6z3hEmq"},"source":[""]}]}